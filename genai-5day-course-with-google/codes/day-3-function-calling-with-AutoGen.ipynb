{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen Function Calling\n",
    "\n",
    "This tutorial will redo the day-3-function-calling-with-llamaIndex.ipynb tutorial using AutoGen.\n",
    "\n",
    "The tutorial demonstrates how to use AutoGen to create agents that translate natural language queries into SQL. We'll focus on:\n",
    "\n",
    "1. Designing effective agents for SQL translation\n",
    "2. Setting up proper agent interactions\n",
    "3. Using function calling to execute database operations\n",
    "4. Creating natural conversations about data\n",
    "\n",
    "First install the autogen-agentchat package.\n",
    "```\n",
    "%pip install autogen-agentchat~=0.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup\n",
    "\n",
    "First, set up the llm connection and sql connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sqlite3\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"api_key\": os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "        \"api_version\": os.getenv(\"OPENAI_API_VERSION\"),\n",
    "        \"base_url\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"config_list\": llm_list,\n",
    "    \"timeout\": 60,\n",
    "}\n",
    "\n",
    "# set up the sql connection\n",
    "db_file = \"sample.db\"\n",
    "db_conn = sqlite3.connect(db_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding AutoGen's Assist Agent and User Proxy\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "AutoGen provides a framework for building conversational AI agents that can interact with each other and with users. Two fundamental agent types in AutoGen are:\n",
    "\n",
    "1. **AssistantAgent (Assist Agent)**\n",
    "   - An AI-powered agent that can understand and respond to queries\n",
    "   - Processes information and generates responses using an LLM\n",
    "   - Can use tools/functions when configured\n",
    "   - Maintains conversation context\n",
    "   - Typically plays the role of the \"expert\" or \"assistant\"\n",
    "\n",
    "2. **UserProxyAgent (User Proxy)**\n",
    "   - Acts as an intermediary between human users and assistant agents\n",
    "   - Can execute code and functions\n",
    "   - Manages user interactions\n",
    "   - Can be configured to run autonomously or require human approval\n",
    "   - Helps maintain conversation flow and state\n",
    "\n",
    "## Implementation Example\n",
    "\n",
    "Let's create a basic example showing how these agents interact:\n",
    "\n",
    "```python\n",
    "import autogen\n",
    "\n",
    "# Configure the assistant\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config={\n",
    "        \"temperature\": 0.7,\n",
    "        \"config_list\": [{\n",
    "            \"model\": \"gpt-4\",\n",
    "            \"api_key\": \"your_api_key\",\n",
    "            \"base_url\": \"your api endpoint\"\n",
    "        }],\n",
    "    },\n",
    "    system_message=\"You are a helpful AI assistant that provides clear and concise answers.\"\n",
    ")\n",
    "\n",
    "# Configure the user proxy\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"TERMINATE\",  # TERMINATE, NEVER, or ALWAYS\n",
    "    max_consecutive_auto_reply=2,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\", # directory for code execution\n",
    "        \"use_docker\": False, \n",
    "    },\n",
    ")\n",
    "```\n",
    "\n",
    "### Key Features\n",
    "\n",
    "#### AssistantAgent Features:\n",
    "- **System Message**: Defines the agent's role and behavior\n",
    "- **LLM Configuration**: Specifies the language model and parameters\n",
    "- **Function Calling**: Can be configured with custom functions\n",
    "- **Memory**: Maintains conversation history\n",
    "\n",
    "#### UserProxyAgent Features:\n",
    "- **Human Input Modes**:\n",
    "  - `TERMINATE`: Asks for human input only when terminating\n",
    "  - `NEVER`: Runs completely autonomously\n",
    "  - `ALWAYS`: Always asks for human input\n",
    "- **Code Execution**: Can execute code in a controlled environment\n",
    "- **Auto-reply Settings**: Controls consecutive automatic responses\n",
    "- **Termination Conditions**: Customizable conversation ending criteria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Design\n",
    "\n",
    "In this section, we will implement the AutoGen function calling feature, which performs the same tasks as described in [function calling with LlamaIndex](day-3-function-calling-with-llamaIndex.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import (\n",
    "    AssistantAgent,\n",
    "    UserProxyAgent\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
